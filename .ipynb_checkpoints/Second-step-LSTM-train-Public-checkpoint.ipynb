{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51f04ac",
   "metadata": {},
   "source": [
    "### Importing The Required Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395cde7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:05:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "tf.__version__\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "714cc022",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"qa\"\n",
    "tokenizer = pickle.load(open('tokenizer/tokenizer-' + filename + '.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04bb18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19687206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Are you a fan of Google or Microsoft? Both are excellent technology they are helpful in many ways. For the security purpose both are super.  I'm not  a huge fan of Google, but I use it a lot because I have to. I think they are a monopoly in some sense.   Google provides online related services and products, which includes online ads, search engine and cloud \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"data/\" + filename + \".txt\", \"r\", encoding = \"utf8\")\n",
    "lines = []\n",
    "l = 0\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "    l = l + 1\n",
    "    if (l > 5):\n",
    "        print(\"The First Line: \", lines[0])\n",
    "        print(\"The Last Line: \", lines[-1])\n",
    "    else:\n",
    "        print(len(lines[0]))\n",
    "data = \"\"\n",
    "\n",
    "for i in lines:\n",
    "    data = ' '. join(lines)\n",
    "\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
    "\n",
    "data[:360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0555f71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "sequence_data[:10]\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e552f16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Length of sequences are:  18077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  80,    3],\n",
       "       [   3, 2607],\n",
       "       [2607, 2116],\n",
       "       [2116,  577],\n",
       "       [ 577,  647],\n",
       "       [ 647,  714],\n",
       "       [ 714, 7019],\n",
       "       [7019,  940],\n",
       "       [ 940,   80],\n",
       "       [  80, 6385]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sequences = []\n",
    "\n",
    "for i in range(1, int(len(sequence_data)/200)):\n",
    "    words = sequence_data[i-1:i+1]\n",
    "    sequences.append(words)\n",
    "    \n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2eb238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Data is:  [  80    3 2607 2116  577]\n",
      "The responses are:  [   3 2607 2116  577  647]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sequences:\n",
    "    X.append(i[0])\n",
    "    y.append(i[1])\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"The Data is: \", X[:5])\n",
    "print(\"The responses are: \", y[:5])\n",
    "\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd0ebe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1, 10)             367690    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 1, 1000)           4044000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1000)              8004000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36769)             36805769  \n",
      "=================================================================\n",
      "Total params: 50,222,459\n",
      "Trainable params: 50,222,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=1))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11bd1c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "keras.utils.plot_model(model, to_file='model.png', show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee3c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"nextword-\"+filename+\".h5\", monitor='loss', verbose=1,\n",
    "    save_best_only=True, mode='auto')\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001, verbose = 1)\n",
    "\n",
    "logdir='logsnextword'+filename\n",
    "tensorboard_Visualization = TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a02339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "283/283 [==============================] - 9s 18ms/step - loss: 7.1351\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.13511, saving model to nextword-qa.h5\n",
      "Epoch 2/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 6.2632\n",
      "\n",
      "Epoch 00002: loss improved from 7.13511 to 6.26320, saving model to nextword-qa.h5\n",
      "Epoch 3/50\n",
      "283/283 [==============================] - 5s 16ms/step - loss: 6.1772\n",
      "\n",
      "Epoch 00003: loss improved from 6.26320 to 6.17721, saving model to nextword-qa.h5\n",
      "Epoch 4/50\n",
      "283/283 [==============================] - 5s 16ms/step - loss: 6.0990\n",
      "\n",
      "Epoch 00004: loss improved from 6.17721 to 6.09901, saving model to nextword-qa.h5\n",
      "Epoch 5/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 5.9329\n",
      "\n",
      "Epoch 00005: loss improved from 6.09901 to 5.93290, saving model to nextword-qa.h5\n",
      "Epoch 6/50\n",
      "283/283 [==============================] - 5s 17ms/step - loss: 5.7306\n",
      "\n",
      "Epoch 00006: loss improved from 5.93290 to 5.73062, saving model to nextword-qa.h5\n",
      "Epoch 7/50\n",
      "283/283 [==============================] - 5s 16ms/step - loss: 5.5595\n",
      "\n",
      "Epoch 00007: loss improved from 5.73062 to 5.55954, saving model to nextword-qa.h5\n",
      "Epoch 8/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 5.4038\n",
      "\n",
      "Epoch 00008: loss improved from 5.55954 to 5.40384, saving model to nextword-qa.h5\n",
      "Epoch 9/50\n",
      "283/283 [==============================] - 5s 16ms/step - loss: 5.2600\n",
      "\n",
      "Epoch 00009: loss improved from 5.40384 to 5.26000, saving model to nextword-qa.h5\n",
      "Epoch 10/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 5.1255\n",
      "\n",
      "Epoch 00010: loss improved from 5.26000 to 5.12552, saving model to nextword-qa.h5\n",
      "Epoch 11/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 4.9953\n",
      "\n",
      "Epoch 00011: loss improved from 5.12552 to 4.99529, saving model to nextword-qa.h5\n",
      "Epoch 12/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 4.8687\n",
      "\n",
      "Epoch 00012: loss improved from 4.99529 to 4.86867, saving model to nextword-qa.h5\n",
      "Epoch 13/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 4.7488\n",
      "\n",
      "Epoch 00013: loss improved from 4.86867 to 4.74885, saving model to nextword-qa.h5\n",
      "Epoch 14/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 4.6304\n",
      "\n",
      "Epoch 00014: loss improved from 4.74885 to 4.63036, saving model to nextword-qa.h5\n",
      "Epoch 15/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 4.5277\n",
      "\n",
      "Epoch 00015: loss improved from 4.63036 to 4.52769, saving model to nextword-qa.h5\n",
      "Epoch 16/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 4.4243\n",
      "\n",
      "Epoch 00016: loss improved from 4.52769 to 4.42433, saving model to nextword-qa.h5\n",
      "Epoch 17/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 4.3477\n",
      "\n",
      "Epoch 00017: loss improved from 4.42433 to 4.34768, saving model to nextword-qa.h5\n",
      "Epoch 18/50\n",
      "283/283 [==============================] - 5s 16ms/step - loss: 4.2785\n",
      "\n",
      "Epoch 00018: loss improved from 4.34768 to 4.27853, saving model to nextword-qa.h5\n",
      "Epoch 19/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 4.1947\n",
      "\n",
      "Epoch 00019: loss improved from 4.27853 to 4.19473, saving model to nextword-qa.h5\n",
      "Epoch 20/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 4.1241\n",
      "\n",
      "Epoch 00020: loss improved from 4.19473 to 4.12412, saving model to nextword-qa.h5\n",
      "Epoch 21/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 4.0591\n",
      "\n",
      "Epoch 00021: loss improved from 4.12412 to 4.05911, saving model to nextword-qa.h5\n",
      "Epoch 22/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 3.9995\n",
      "\n",
      "Epoch 00022: loss improved from 4.05911 to 3.99947, saving model to nextword-qa.h5\n",
      "Epoch 23/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.9464\n",
      "\n",
      "Epoch 00023: loss improved from 3.99947 to 3.94639, saving model to nextword-qa.h5\n",
      "Epoch 24/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.8839\n",
      "\n",
      "Epoch 00024: loss improved from 3.94639 to 3.88386, saving model to nextword-qa.h5\n",
      "Epoch 25/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.8391\n",
      "\n",
      "Epoch 00025: loss improved from 3.88386 to 3.83906, saving model to nextword-qa.h5\n",
      "Epoch 26/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 3.7790\n",
      "\n",
      "Epoch 00026: loss improved from 3.83906 to 3.77898, saving model to nextword-qa.h5\n",
      "Epoch 27/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.7316\n",
      "\n",
      "Epoch 00027: loss improved from 3.77898 to 3.73160, saving model to nextword-qa.h5\n",
      "Epoch 28/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 3.6762\n",
      "\n",
      "Epoch 00028: loss improved from 3.73160 to 3.67619, saving model to nextword-qa.h5\n",
      "Epoch 29/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 3.6346\n",
      "\n",
      "Epoch 00029: loss improved from 3.67619 to 3.63463, saving model to nextword-qa.h5\n",
      "Epoch 30/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.5985\n",
      "\n",
      "Epoch 00030: loss improved from 3.63463 to 3.59848, saving model to nextword-qa.h5\n",
      "Epoch 31/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.5545\n",
      "\n",
      "Epoch 00031: loss improved from 3.59848 to 3.55445, saving model to nextword-qa.h5\n",
      "Epoch 32/50\n",
      "283/283 [==============================] - 5s 16ms/step - loss: 3.5173\n",
      "\n",
      "Epoch 00032: loss improved from 3.55445 to 3.51731, saving model to nextword-qa.h5\n",
      "Epoch 33/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.4868\n",
      "\n",
      "Epoch 00033: loss improved from 3.51731 to 3.48681, saving model to nextword-qa.h5\n",
      "Epoch 34/50\n",
      "283/283 [==============================] - 5s 18ms/step - loss: 3.4488\n",
      "\n",
      "Epoch 00034: loss improved from 3.48681 to 3.44878, saving model to nextword-qa.h5\n",
      "Epoch 35/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 3.4211\n",
      "\n",
      "Epoch 00035: loss improved from 3.44878 to 3.42114, saving model to nextword-qa.h5\n",
      "Epoch 36/50\n",
      "283/283 [==============================] - 5s 16ms/step - loss: 3.3941\n",
      "\n",
      "Epoch 00036: loss improved from 3.42114 to 3.39410, saving model to nextword-qa.h5\n",
      "Epoch 37/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.3681\n",
      "\n",
      "Epoch 00037: loss improved from 3.39410 to 3.36815, saving model to nextword-qa.h5\n",
      "Epoch 38/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.3447\n",
      "\n",
      "Epoch 00038: loss improved from 3.36815 to 3.34468, saving model to nextword-qa.h5\n",
      "Epoch 39/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 3.3184\n",
      "\n",
      "Epoch 00039: loss improved from 3.34468 to 3.31839, saving model to nextword-qa.h5\n",
      "Epoch 40/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 3.2951\n",
      "\n",
      "Epoch 00040: loss improved from 3.31839 to 3.29512, saving model to nextword-qa.h5\n",
      "Epoch 41/50\n",
      "283/283 [==============================] - 5s 16ms/step - loss: 3.2793\n",
      "\n",
      "Epoch 00041: loss improved from 3.29512 to 3.27933, saving model to nextword-qa.h5\n",
      "Epoch 42/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 3.2607\n",
      "\n",
      "Epoch 00042: loss improved from 3.27933 to 3.26066, saving model to nextword-qa.h5\n",
      "Epoch 43/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.2449\n",
      "\n",
      "Epoch 00043: loss improved from 3.26066 to 3.24493, saving model to nextword-qa.h5\n",
      "Epoch 44/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.2228\n",
      "\n",
      "Epoch 00044: loss improved from 3.24493 to 3.22282, saving model to nextword-qa.h5\n",
      "Epoch 45/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 3.2137\n",
      "\n",
      "Epoch 00045: loss improved from 3.22282 to 3.21373, saving model to nextword-qa.h5\n",
      "Epoch 46/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 3.1941\n",
      "\n",
      "Epoch 00046: loss improved from 3.21373 to 3.19409, saving model to nextword-qa.h5\n",
      "Epoch 47/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.1874\n",
      "\n",
      "Epoch 00047: loss improved from 3.19409 to 3.18736, saving model to nextword-qa.h5\n",
      "Epoch 48/50\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 3.1699\n",
      "\n",
      "Epoch 00048: loss improved from 3.18736 to 3.16985, saving model to nextword-qa.h5\n",
      "Epoch 49/50\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 3.1592\n",
      "\n",
      "Epoch 00049: loss improved from 3.16985 to 3.15920, saving model to nextword-qa.h5\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 4s 16ms/step - loss: 3.1461\n",
      "\n",
      "Epoch 00050: loss improved from 3.15920 to 3.14614, saving model to nextword-qa.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x133261d5a58>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, batch_size=64, callbacks=[checkpoint, reduce, tensorboard_Visualization])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b0eb06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/26649716/how-to-show-pil-image-in-ipython-notebook\n",
    "# tensorboard --logdir=\"./logsnextword1\"\n",
    "# http://DESKTOP-U3TSCVT:6006/\n",
    "\n",
    "from IPython.display import Image \n",
    "pil_img = Image(filename='graph1.png')\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b52fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
